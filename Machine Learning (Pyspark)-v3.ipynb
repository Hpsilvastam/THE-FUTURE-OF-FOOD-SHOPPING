{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.session import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "aisles = spark.read \\\n",
    "    .options(header=True, inferSchema=True) \\\n",
    "    .csv(\"D:/DADOS USUARIO/Documents/springboard/capstone project/Instacart Kaggle/aisles.csv\")\n",
    "dptmts = sqlContext.read \\\n",
    "    .options(header=True, inferSchema=True) \\\n",
    "    .csv(\"D:/DADOS USUARIO/Documents/springboard/capstone project/Instacart Kaggle/departments.csv\")\n",
    "prod_in_orders = sqlContext.read \\\n",
    "    .options(header=True, inferSchema=True) \\\n",
    "    .csv(\"D:/DADOS USUARIO/Documents/springboard/capstone project/Instacart Kaggle/order_products__prior.csv\")\n",
    "all_orders = sqlContext.read \\\n",
    "    .options(header=True, inferSchema=True) \\\n",
    "    .csv(\"D:/DADOS USUARIO/Documents/springboard/capstone project/Instacart Kaggle/orders.csv\")\n",
    "train = sqlContext.read \\\n",
    "    .options(header=True, inferSchema=True) \\\n",
    "    .csv(\"D:/DADOS USUARIO/Documents/springboard/capstone project/Instacart Kaggle/order_products__train.csv\")\n",
    "products = sqlContext.read \\\n",
    "    .options(header=True, inferSchema=True) \\\n",
    "    .csv(\"D:/DADOS USUARIO/Documents/springboard/capstone project/Instacart Kaggle/products.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Merge of products, aisles and departments and delete dptmns & aisles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[department_id: int, department: string]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The first join will connect the products tables\n",
    "prod_full = products.join(aisles, on='aisle_id')\n",
    "prod_full = prod_full.join(dptmts, on='department_id')\n",
    "#delete aisles and dptmts dataframes\n",
    "aisles.unpersist()\n",
    "dptmts.unpersist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Add the User_id to the prior and train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#add user_id to train\n",
    "train = train.join(all_orders, on='order_id')\n",
    "train = train.drop('eval_set','order_number','order_dow','order_hour_of_day','days_since_prior_order')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Inner join entre all orders e prod in orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[order_id: int, product_id: int, add_to_cart_order: int, reordered: int]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#add user_id to prior\n",
    "orders_prod = prod_in_orders.join(all_orders, on='order_id')\n",
    "prod_in_orders.unpersist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- order_id: integer (nullable = true)\n",
      " |-- product_id: integer (nullable = true)\n",
      " |-- add_to_cart_order: integer (nullable = true)\n",
      " |-- reordered: integer (nullable = true)\n",
      " |-- user_id: integer (nullable = true)\n",
      " |-- eval_set: string (nullable = true)\n",
      " |-- order_number: integer (nullable = true)\n",
      " |-- order_dow: integer (nullable = true)\n",
      " |-- order_hour_of_day: integer (nullable = true)\n",
      " |-- days_since_prior_order: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "orders_prod.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - Features from Products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import Window\n",
    "windowval2 = Window.partitionBy('user_id', 'product_id').orderBy(['user_id', 'order_number', 'product_id']).rangeBetween(Window.unboundedPreceding, 0)\n",
    "orders_prod = orders_prod.withColumn('prod_user_times', F.count('order_id').over(windowval2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "windowval3 = Window.partitionBy('product_id').orderBy('product_id').rangeBetween(Window.unboundedPreceding, 0)\n",
    "orders_prod = orders_prod.withColumn('n_times_prod_ordered', F.count('order_id').over(windowval3))\n",
    "orders_prod = orders_prod.withColumn('n_times_prod_reordered', F.sum('reordered').over(windowval3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prod = orders_prod\n",
    "prod1 = prod.select('product_id', 'prod_user_times').filter(prod.prod_user_times == 1).groupby('product_id').sum('prod_user_times')\n",
    "prod2 = prod.select('product_id', 'prod_user_times').filter(prod.prod_user_times == 2).groupby('product_id').sum('prod_user_times')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prod1 = prod1.sort(\"product_id\")\n",
    "prod2 = prod2.sort(\"product_id\")\n",
    "prod1 = prod1.withColumnRenamed(\"sum(prod_user_times)\", \"first_ord_prod\")\n",
    "prod2 = prod2.withColumnRenamed(\"sum(prod_user_times)\", \"second_ord_prod\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prod = prod.drop('order_id','add_to_cart_order', 'reordered','user_id','eval_set','order_number','order_dow','order_hour_of_day','days_since_prior_order','prod_user_times')\n",
    "prod = prod.groupby('product_id').agg({'n_times_prod_ordered': 'max', 'n_times_prod_reordered': 'max'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prod = prod.sort(\"product_id\")\n",
    "prod = prod.withColumnRenamed(\"max(n_times_prod_ordered)\", \"times_prod_ordered\")\n",
    "prod = prod.withColumnRenamed(\"max(n_times_prod_reordered)\", \"times_prod_reordered\")\n",
    "prod = prod.join(prod1, on='product_id')\n",
    "prod = prod.join(prod2, on='product_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prod = prod.withColumn('prod_reorder_probability', prod.second_ord_prod / prod.first_ord_prod)\n",
    "prod = prod.withColumn('prod_reorder_times', 1 + prod.times_prod_reordered / prod.first_ord_prod)\n",
    "prod = prod.withColumn('prod_reorder_ratio', prod.times_prod_reordered / prod.times_prod_ordered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[product_id: int, second_ord_prod: bigint]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prod1.unpersist()\n",
    "prod2.unpersist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prod = prod.drop('times_prod_reordered', 'first_ord_prod', 'second_ord_prod')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- product_id: integer (nullable = true)\n",
      " |-- times_prod_ordered: long (nullable = true)\n",
      " |-- prod_reorder_probability: double (nullable = true)\n",
      " |-- prod_reorder_times: double (nullable = true)\n",
      " |-- prod_reorder_ratio: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prod.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 - Features from Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "users = all_orders.filter(all_orders.eval_set == 'prior')\n",
    "users = users.withColumn('dspo', users.days_since_prior_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- order_id: integer (nullable = true)\n",
      " |-- user_id: integer (nullable = true)\n",
      " |-- eval_set: string (nullable = true)\n",
      " |-- order_number: integer (nullable = true)\n",
      " |-- order_dow: integer (nullable = true)\n",
      " |-- order_hour_of_day: integer (nullable = true)\n",
      " |-- days_since_prior_order: double (nullable = true)\n",
      " |-- dspo: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "users.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "users = users.groupby('user_id').agg({'order_number': 'max', 'days_since_prior_order': 'sum', 'dspo': 'mean'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "us = orders_prod.groupby('user_id').count()\n",
    "us = us.withColumnRenamed(\"count\", \"user_total_prod\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "us1 = orders_prod.select('user_id', 'reordered').filter(orders_prod.reordered == 1).groupby('user_id').sum('reordered')\n",
    "us2 = orders_prod.select('user_id', 'order_number').filter(orders_prod.order_number > 1).groupby('user_id').sum('order_number')\n",
    "us3 = us1.join(us2, on='user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "us3 = us3.withColumnRenamed(\"sum(reordered)\", \"reord\")\n",
    "us3 = us3.withColumnRenamed(\"sum(order_number)\", \"on\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "us3 = us3.withColumn('user_reorder_ratio', us3.reord / us3.on)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "us3 = us3.drop('reord', 'on')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import countDistinct\n",
    "us4 = orders_prod.groupBy(\"user_id\").agg(countDistinct(\"product_id\"))\n",
    "us4 = us4.withColumnRenamed('count(DISTINCT product_id)', 'distinct')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "us = us.join(us1, on='user_id')\n",
    "us = us.join(us2, on='user_id')\n",
    "us = us.join(us3, on='user_id')\n",
    "us = us.join(us4, on='user_id')\n",
    "users = users.join(us, on='user_id')\n",
    "users = users.withColumnRenamed('max(order_number)', 'user_orders')\n",
    "users = users.withColumnRenamed('avg(dspo)', 'user_mean_days_since_prior')\n",
    "users = users.withColumnRenamed('sum(days_since_prior_order)', 'user_period')\n",
    "users = users.withColumnRenamed('sum(reordered)', 'sum_reordered')\n",
    "users = users.withColumnRenamed('sum(order_number)', 'sum_order_number')\n",
    "users = users.drop('sum_reordered', 'sum_order_number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "users = users.withColumn('user_average_basket', users.user_total_prod / users.user_orders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "us_orders = all_orders.select('user_id', 'order_id', 'eval_set', 'days_since_prior_order').filter(all_orders.eval_set != 'prior')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "users = users.join(us_orders, on='user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[user_id: int, order_id: int, eval_set: string, days_since_prior_order: double]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "us.unpersist()\n",
    "us1.unpersist()\n",
    "us2.unpersist()\n",
    "us3.unpersist()\n",
    "us4.unpersist()\n",
    "us_orders.unpersist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- user_id: integer (nullable = true)\n",
      " |-- user_mean_days_since_prior: double (nullable = true)\n",
      " |-- user_orders: integer (nullable = true)\n",
      " |-- user_period: double (nullable = true)\n",
      " |-- user_total_prod: long (nullable = false)\n",
      " |-- user_reorder_ratio: double (nullable = true)\n",
      " |-- distinct: long (nullable = false)\n",
      " |-- user_average_basket: double (nullable = true)\n",
      " |-- order_id: integer (nullable = true)\n",
      " |-- eval_set: string (nullable = true)\n",
      " |-- days_since_prior_order: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "users.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 - Create a Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = orders_prod.withColumn('order_number2', orders_prod.order_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "windowval4 = Window.partitionBy('user_id', 'product_id').rangeBetween(Window.unboundedPreceding, 0)\n",
    "data = data.withColumn('count_order_id', F.min('order_id').over(windowval4))\n",
    "data = data.withColumn('min_order_number', F.min('order_number').over(windowval4))\n",
    "data = data.withColumn('max_order_number', F.max('order_number2').over(windowval4))\n",
    "data = data.withColumn('mean_add_to_cart_order', F.avg('add_to_cart_order').over(windowval4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = data.drop('eval_set', 'order_id', 'reordered')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = data.join(prod, on='product_id')\n",
    "data = data.join(users, on='user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = data.withColumn('up_order_rate', data.count_order_id / data.user_orders)\n",
    "data = data.withColumn('up_orders_since_last_order', data.user_orders - data.max_order_number)\n",
    "data = data.withColumn('up_order_rate_since_first_order', data.count_order_id / (data.user_orders - data.min_order_number + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = train.select('user_id', 'product_id', 'reordered')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = data.join(train, on=['user_id','product_id'], how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = data.drop(\"days_since_prior_order\", \"order_number2\", 'add_to_cart_order', 'order_dow', 'order_hour_of_day')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- user_id: integer (nullable = true)\n",
      " |-- product_id: integer (nullable = true)\n",
      " |-- order_number: integer (nullable = true)\n",
      " |-- prod_user_times: long (nullable = true)\n",
      " |-- n_times_prod_ordered: long (nullable = true)\n",
      " |-- n_times_prod_reordered: long (nullable = true)\n",
      " |-- count_order_id: integer (nullable = true)\n",
      " |-- min_order_number: integer (nullable = true)\n",
      " |-- max_order_number: integer (nullable = true)\n",
      " |-- mean_add_to_cart_order: double (nullable = true)\n",
      " |-- times_prod_ordered: long (nullable = true)\n",
      " |-- prod_reorder_probability: double (nullable = true)\n",
      " |-- prod_reorder_times: double (nullable = true)\n",
      " |-- prod_reorder_ratio: double (nullable = true)\n",
      " |-- user_mean_days_since_prior: double (nullable = true)\n",
      " |-- user_orders: integer (nullable = true)\n",
      " |-- user_period: double (nullable = true)\n",
      " |-- user_total_prod: long (nullable = true)\n",
      " |-- user_reorder_ratio: double (nullable = true)\n",
      " |-- distinct: long (nullable = true)\n",
      " |-- user_average_basket: double (nullable = true)\n",
      " |-- order_id: integer (nullable = true)\n",
      " |-- eval_set: string (nullable = true)\n",
      " |-- up_order_rate: double (nullable = true)\n",
      " |-- up_orders_since_last_order: integer (nullable = true)\n",
      " |-- up_order_rate_since_first_order: double (nullable = true)\n",
      " |-- reordered: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[user_id: int, user_mean_days_since_prior: double, user_orders: int, user_period: double, user_total_prod: bigint, user_reorder_ratio: double, distinct: bigint, user_average_basket: double, order_id: int, eval_set: string, days_since_prior_order: double]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_orders.unpersist()\n",
    "train.unpersist()\n",
    "products.unpersist()\n",
    "prod_full.unpersist()\n",
    "orders_prod.unpersist()\n",
    "prod.unpersist()\n",
    "users.unpersist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7 - Train and Test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = data.filter(data.eval_set == 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = train.drop('eval_set', 'user_id', 'product_id', 'order_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = train.na.fill(0, subset=['reordered'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = data.filter(data.eval_set == 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = test.drop('eval_set', 'user_id', 'reordered')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[user_id: int, product_id: int, order_number: int, prod_user_times: bigint, n_times_prod_ordered: bigint, n_times_prod_reordered: bigint, count_order_id: int, min_order_number: int, max_order_number: int, mean_add_to_cart_order: double, times_prod_ordered: bigint, prod_reorder_probability: double, prod_reorder_times: double, prod_reorder_ratio: double, user_mean_days_since_prior: double, user_orders: int, user_period: double, user_total_prod: bigint, user_reorder_ratio: double, distinct: bigint, user_average_basket: double, order_id: int, eval_set: string, up_order_rate: double, up_orders_since_last_order: int, up_order_rate_since_first_order: double, reordered: int]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.unpersist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- order_number: integer (nullable = true)\n",
      " |-- prod_user_times: long (nullable = true)\n",
      " |-- n_times_prod_ordered: long (nullable = true)\n",
      " |-- n_times_prod_reordered: long (nullable = true)\n",
      " |-- count_order_id: integer (nullable = true)\n",
      " |-- min_order_number: integer (nullable = true)\n",
      " |-- max_order_number: integer (nullable = true)\n",
      " |-- mean_add_to_cart_order: double (nullable = true)\n",
      " |-- times_prod_ordered: long (nullable = true)\n",
      " |-- prod_reorder_probability: double (nullable = true)\n",
      " |-- prod_reorder_times: double (nullable = true)\n",
      " |-- prod_reorder_ratio: double (nullable = true)\n",
      " |-- user_mean_days_since_prior: double (nullable = true)\n",
      " |-- user_orders: integer (nullable = true)\n",
      " |-- user_period: double (nullable = true)\n",
      " |-- user_total_prod: long (nullable = true)\n",
      " |-- user_reorder_ratio: double (nullable = true)\n",
      " |-- distinct: long (nullable = true)\n",
      " |-- user_average_basket: double (nullable = true)\n",
      " |-- up_order_rate: double (nullable = true)\n",
      " |-- up_orders_since_last_order: integer (nullable = true)\n",
      " |-- up_order_rate_since_first_order: double (nullable = true)\n",
      " |-- reordered: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- product_id: integer (nullable = true)\n",
      " |-- order_number: integer (nullable = true)\n",
      " |-- prod_user_times: long (nullable = true)\n",
      " |-- n_times_prod_ordered: long (nullable = true)\n",
      " |-- n_times_prod_reordered: long (nullable = true)\n",
      " |-- count_order_id: integer (nullable = true)\n",
      " |-- min_order_number: integer (nullable = true)\n",
      " |-- max_order_number: integer (nullable = true)\n",
      " |-- mean_add_to_cart_order: double (nullable = true)\n",
      " |-- times_prod_ordered: long (nullable = true)\n",
      " |-- prod_reorder_probability: double (nullable = true)\n",
      " |-- prod_reorder_times: double (nullable = true)\n",
      " |-- prod_reorder_ratio: double (nullable = true)\n",
      " |-- user_mean_days_since_prior: double (nullable = true)\n",
      " |-- user_orders: integer (nullable = true)\n",
      " |-- user_period: double (nullable = true)\n",
      " |-- user_total_prod: long (nullable = true)\n",
      " |-- user_reorder_ratio: double (nullable = true)\n",
      " |-- distinct: long (nullable = true)\n",
      " |-- user_average_basket: double (nullable = true)\n",
      " |-- order_id: integer (nullable = true)\n",
      " |-- up_order_rate: double (nullable = true)\n",
      " |-- up_orders_since_last_order: integer (nullable = true)\n",
      " |-- up_order_rate_since_first_order: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8 - Write the data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.coalesce(1).write.format(\"com.databricks.spark.csv\").option(\"header\", \"true\").save(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test.coalesce(1).write.format(\"com.databricks.spark.csv\").option(\"header\", \"true\").save(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from pyspark.sql import Window\n",
    "\n",
    "#windowval = Window.partitionBy('user_id').orderBy('order_number').rangeBetween(Window.unboundedPreceding, 0)\n",
    "#windowval2 = Window.partitionBy('user_id', 'product_id').orderBy('order_number')\n",
    "#all_orders = all_orders.withColumn('dspo_cum_sum', F.sum('days_since_prior_order').over(windowval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from pyspark.sql import Window\n",
    "#opf = order_prod_full\n",
    "#windowval = Window.partitionBy('user_id','product_id').orderBy('order_number').rangeBetween(Window.unboundedPreceding, 0)\n",
    "#opf = opf.withColumn('MIN_dspo_cum_sum', F.min('dspo_cum_sum').over(windowval))\n",
    "#opf = opf.withColumn('MAX_dspo_cum_sum', F.max('dspo_cum_sum').over(windowval))\n",
    "#opf = opf.withColumn('COUNT_dspo_cum_sum', F.count('dspo_cum_sum').over(windowval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#opf = opf.withColumn('SND_MAX_dspo_cum_sum', F.lag('dspo_cum_sum',1,0).over(windowval2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#opf = opf.withColumn('DIFF_dspo_cum_sum', opf.MAX_dspo_cum_sum - opf.MIN_dspo_cum_sum)\n",
    "#opf = opf.withColumn('DIFF2_dspo_cum_sum', opf.MAX_dspo_cum_sum - opf.SND_MAX_dspo_cum_sum)\n",
    "#opf = opf.withColumn('fixed_freq', opf.DIFF_dspo_cum_sum / (opf.COUNT_dspo_cum_sum - 1))\n",
    "#opf = opf.withColumn('flex_freq_1', opf.DIFF2_dspo_cum_sum / (opf.COUNT_dspo_cum_sum - 1))\n",
    "#opf = opf.withColumn('flex_freq_2', opf.DIFF2_dspo_cum_sum / (opf.COUNT_dspo_cum_sum - 1))\n",
    "#opf = opf.withColumnRenamed('COUNT_dspo_cum_sum', 'count_user_prod')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#opf = opf.drop('order_id', 'add_to_cart_order', 'reordered', 'eval_set', 'order_dow', 'order_hour_of_day', 'department_id', 'aisle_id', 'product_name', 'aisle', 'department')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#opf2 = opf.groupby(['user_id', 'product_id']).agg({'count_user_prod': 'max', 'flex_freq_1': 'mean', 'flex_freq_2': 'stddev_pop'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#opf2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#3opf2.coalesce(1).write.format(\"com.databricks.spark.csv\").option(\"header\", \"true\").save(\"opf2.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
